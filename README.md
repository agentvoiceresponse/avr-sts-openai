# Agent Voice Response - OpenAI Speech-to-Speech Integration

[![Discord](https://img.shields.io/discord/1347239846632226998?label=Discord&logo=discord)](https://discord.gg/DFTU69Hg74)
[![GitHub Repo stars](https://img.shields.io/github/stars/agentvoiceresponse/avr-sts-openai?style=social)](https://github.com/agentvoiceresponse/avr-sts-openai)
[![Docker Pulls](https://img.shields.io/docker/pulls/agentvoiceresponse/avr-sts-openai?label=Docker%20Pulls&logo=docker)](https://hub.docker.com/r/agentvoiceresponse/avr-sts-openai)
[![Ko-fi](https://img.shields.io/badge/Support%20us%20on-Ko--fi-ff5e5b.svg)](https://ko-fi.com/agentvoiceresponse)

This repository is part of the **Agent Voice Response (AVR)** ecosystem, providing a direct integration with OpenAI's Real-time Speech-to-Speech API. This integration allows AVR to handle voice interactions with OpenAI's advanced language models, enabling natural conversations between users and AI agents.

## Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Integration with AVR](#integration-with-avr)
- [Troubleshooting](#troubleshooting)
- [Community](#community)
- [Support](#support)
- [License](#license)

## Overview

This integration provides a direct speech-to-speech communication channel with OpenAI's real-time API, eliminating the need for separate ASR and TTS services. The service handles:

1. **Audio Processing**: Converts between 8kHz and 24kHz audio formats
2. **Real-time Streaming**: Manages WebSocket communication with OpenAI
3. **Audio Format Conversion**: Handles necessary audio format transformations

### Integration Flow

<div align="center">
  <img src="https://github.com/agentvoiceresponse/.github/blob/main/profile/images/avr-architecture.png" alt="AVR Architecture" width="600">
  <br>
  <em>AVR Architecture with OpenAI Speech-to-Speech Integration</em>
</div>

## Features

- **Direct Speech-to-Speech**: Eliminates the need for separate ASR and TTS services
- **Real-time Processing**: Handles audio streaming with minimal latency
- **Audio Format Conversion**: Automatic conversion between 8kHz and 24kHz formats
- **WebSocket Communication**: Efficient real-time communication with OpenAI's API
- **Error Handling**: Robust error handling and recovery mechanisms

## Prerequisites

To set up and run this project, you will need:

1. **Node.js** and **npm** installed
2. An **OpenAI API key** with access to the real-time API
3. **WebSocket** support in your environment
4. **Docker** (optional, for containerized deployment)

## Installation

### 1. Clone the Repository

```bash
git clone https://github.com/agentvoiceresponse/avr-sts-openai.git
cd avr-sts-openai
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Configure Environment Variables

Create a `.env` file in the root of the project with the following variables:

```bash
OPENAI_API_KEY=your_openai_api_key
PORT=6030
OPENAI_MODEL=gpt-4o-realtime-preview  # Optional, defaults to gpt-4o-realtime-preview
OPENAI_INSTRUCTIONS="You are a helpful assistant that can answer questions and help with tasks."  # Optional
OPENAI_TEMPERATURE=0.8  # Optional, controls randomness (0.0-1.0), defaults to 0.8
OPENAI_MAX_TOKENS=100  # Optional, controls response length, defaults to 100
```

### 4. Running the Application

Start the application:

```bash
node index.js
```

The server will start on the port defined in the environment variable (default: 6030).

## Integration with AVR

To integrate this service with AVR Core:

1. **Configure AVR Core**:
   - Set the `LLM_URL` environment variable in AVR Core to point to this service:
     ```bash
     LLM_URL=http://localhost:6030/speech-to-speech-stream
     ```

2. **Audio Format**:
   - Ensure your Asterisk configuration is set to use 8kHz audio
   - The service will automatically handle the conversion to 24kHz for OpenAI

## API Endpoints

### POST `/speech-to-speech-stream`

This endpoint accepts an audio stream and returns a streamed audio response generated by OpenAI.

**Request:**
- Content-Type: audio/x-raw
- Format: 16-bit PCM at 8kHz
- Method: POST

**Response:**
- Content-Type: text/event-stream
- Format: 16-bit PCM at 8kHz
- Streamed audio data in real-time

## Troubleshooting

Common issues and solutions:

1. **WebSocket Connection Issues**:
   - Verify OpenAI API key is valid
   - Check network connectivity
   - Ensure WebSocket support is enabled

2. **Audio Quality Issues**:
   - Verify input audio is 8kHz
   - Check audio format compatibility
   - Monitor system resources

3. **Performance Issues**:
   - Check OpenAI API rate limits
   - Monitor system resources
   - Verify network latency

## Community

Join our growing community:

- [Discord Server](https://discord.gg/DFTU69Hg74) - Connect with other AVR users
- [GitHub Discussions](https://github.com/agentvoiceresponse/avr-sts-openai/discussions) - Share ideas and get help
- [Documentation](https://wiki.agentvoiceresponse.com) - Detailed guides and tutorials

## Support

AVR is free and open-source. If you find it valuable, consider supporting its development:

<a href="https://ko-fi.com/agentvoiceresponse" target="_blank"><img src="https://ko-fi.com/img/githubbutton_sm.svg" alt="Support us on Ko-fi"></a>

## License

MIT License - see the [LICENSE](LICENSE.md) file for details.